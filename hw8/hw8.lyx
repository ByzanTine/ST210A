#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\begin_modules
theorems-ams-bytype
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
ST210A - Homework 8
\end_layout

\begin_layout Author
Hoang Duong
\end_layout

\begin_layout Problem
Binomial - Empirical Bayes
\end_layout

\begin_layout Proof
(a) We have the conditional density of 
\begin_inset Formula $X$
\end_inset

 given 
\begin_inset Formula $\Theta$
\end_inset

 is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat}{1}
p_{X\mid\Theta}(x)= & \prod_{i=1}^{p}{m \choose x_{i}}\theta_{i}^{x_{i}}(1-\theta_{i})^{m-x_{i}}
\end{alignat}

\end_inset


\end_layout

\begin_layout Proof
The marginal density of 
\begin_inset Formula $\Theta$
\end_inset

 is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat}{1}
p_{\Theta}(\theta)= & \prod_{i=1}^{p}\frac{1}{B(\alpha,\beta)}\theta_{i}^{\alpha-1}(1-\theta_{i})^{\beta-1}
\end{alignat}

\end_inset


\end_layout

\begin_layout Proof
Multiplying these together, we have the joint density of 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $\Theta$
\end_inset

 is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat}{1}
p_{X,\Theta}= & \prod_{i=1}^{p}\frac{{m \choose x_{i}}}{B(\alpha,\beta)}\theta_{i}^{x_{i}+\alpha-1}(1-\theta_{i})^{\beta+m-x_{i}-1}
\end{alignat}

\end_inset


\end_layout

\begin_layout Proof
Integrating this against 
\begin_inset Formula $\theta,$
\end_inset

 the marginal density of 
\begin_inset Formula $X$
\end_inset

 is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat}{1}
p_{X}= & \int...\int\prod_{i=1}^{p}\frac{{m \choose x_{i}}}{B(\alpha,\beta)}\theta_{i}^{x_{i}+\alpha-1}(1-\theta_{i})^{\beta+m-x_{i}-1}d\theta\\
= & \prod_{i=1}^{p}{m \choose x_{i}}\frac{B(\alpha+x_{i},\beta+m-x_{i})}{B(\alpha,\beta)}\label{eq:5}
\end{alignat}

\end_inset


\end_layout

\begin_layout Proof
Thus we have the conditional density of 
\begin_inset Formula $\Theta$
\end_inset

 given 
\begin_inset Formula $X$
\end_inset

 is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
p_{\Theta\mid X}= & \frac{p_{\Theta,X}}{p_{X}}\\
= & \prod_{i=1}^{p}\frac{1}{B(\alpha+x_{i},\beta+m-x_{i})}\theta_{i}^{x_{i}+\alpha-1}(1-\theta_{i})^{\beta+m-x_{i}-1}\\
\Theta_{i}\mid X\sim & Beta(\alpha+x_{i},\beta+m-x_{i})
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
Since the loss function is quadratic, the Bayes estimator is thus the posterior
 mean:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
\hat{\Theta}_{i}= & \frac{\alpha+x_{i}}{\alpha+\beta+m}
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
(b) For each 
\begin_inset Formula $X_{i}$
\end_inset

 we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
\mathbb{E}\Theta_{i}= & \frac{\alpha}{\alpha+\beta}\\
\mathbb{E}\Theta_{i}^{2}= & {\rm Var}\Theta_{i}+\left(\mathbb{E}\Theta_{i}\right)^{2}\\
= & \frac{\alpha\beta}{(\alpha+\beta)^{2}(\alpha+\beta+1)}+\frac{\alpha^{2}}{(\alpha+\beta)^{2}}\\
= & \frac{\alpha\beta+\alpha^{2}(\alpha+\beta+1)}{(\alpha+\beta)^{2}(\alpha+\beta+1)}\\
= & \frac{(\alpha+\beta)(\alpha^{2}+\alpha)}{(\alpha+\beta)^{2}(\alpha+\beta+1)}\\
= & \frac{\alpha(\alpha+1)}{(\alpha+\beta)(\alpha+\beta+1)}\\
\mathbb{E}\left[X_{i}\right]= & \mathbb{E}\left[\mathbb{E}\left[X_{i}\mid\Theta_{i}\right]\right]\\
= & \mathbb{E}\left[\Theta_{i}m\right]=\frac{m\alpha}{\alpha+\beta}\\
\Rightarrow\frac{\beta}{\alpha}= & \frac{m}{\mathbb{E}X_{i}}-1=\frac{m-\mathbb{E}X_{i}}{\mathbb{E}X_{i}}\\
\mathbb{E}\left[X_{i}^{2}\right]= & \mathbb{E}\left[\mathbb{E}\left[X_{i}^{2}\mid\Theta_{i}\right]\right]\\
= & \mathbb{E}\left[m\Theta_{i}-m\Theta_{i}^{2}+m^{2}\Theta_{i}^{2}\right]\\
= & \frac{m\alpha}{\alpha+\beta}+\frac{m(m-1)\alpha(\alpha+1)}{(\alpha+\beta)(\alpha+\beta+1)}\\
= & \mathbb{E}X_{i}+\frac{\alpha+1}{\alpha+\beta+1}(m-1)\mathbb{E}X_{i}\\
\Rightarrow\frac{\beta}{\alpha+1}= & \frac{(m-1)\mathbb{E}X_{i}}{\mathbb{E}X_{i}^{2}-\mathbb{E}X_{i}}-1\\
\Rightarrow\frac{\alpha+1}{\alpha}= & \frac{m-\mathbb{E}X_{i}}{\mathbb{E}X_{i}}\frac{\mathbb{E}X_{i}^{2}-\mathbb{E}X_{i}}{m\mathbb{E}X_{i}-\mathbb{E}X_{i}^{2}}\\
\Rightarrow\frac{1}{\alpha}= & \frac{md-mc-cd+c^{2}-mc^{2}+cd}{c(mc-d)}\\
= & \frac{md-mc+c^{2}-mc^{2}}{c(mc-d)}\\
\Rightarrow\alpha= & \frac{c(mc-d)}{md-mc+c^{2}-mc^{2}}\\
\Rightarrow\beta= & \alpha\frac{m-c}{c}=\frac{c(mc-d)(m-c)}{c(md-mc+c^{2}-mc^{2})}\\
= & \frac{(mc-d)(m-c)}{md-mc+c^{2}-mc^{2}}
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
For 
\begin_inset Formula $c=\mathbb{E}X_{i},d=\mathbb{E}X_{i}^{2}.$
\end_inset

 So using method of moment, we can calculate the sample mean and sample
 
\begin_inset Formula $\frac{1}{p-1}\sum X_{i}^{2}$
\end_inset

 to plug in the formula of 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 above, and we will get estimators for 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

.
 
\end_layout

\begin_layout Proof
(c) Combining (a) and (b) we get the empirical Bayes estimator for 
\begin_inset Formula $\theta_{i}$
\end_inset

 is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
 & \frac{\hat{\alpha}+x_{i}}{\hat{\alpha}+\hat{\beta}+m}\\
\hat{\alpha}= & \frac{c(mc-d)}{md-mc+c^{2}-mc^{2}}\\
\hat{\beta}= & \frac{(mc-d)(m-c)}{md-mc+c^{2}-mc^{2}}\\
c= & \frac{1}{p}\sum_{i=1}^{p}X_{i}\\
d= & \frac{1}{p-1}\sum_{i=1}^{p}X_{i}^{2}
\end{alignat*}

\end_inset


\end_layout

\begin_layout Problem
UMP for Uniform Distribution 
\begin_inset Formula $[0,\theta]$
\end_inset


\end_layout

\begin_layout Proof
(a) We use the order statistics notation of 
\begin_inset Formula $x_{(1)},...,x_{(n)}.$
\end_inset

 The density 
\begin_inset Formula $p_{\theta}$
\end_inset

 for a uniform distribution on 
\begin_inset Formula $[0,\theta]$
\end_inset

 is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
p_{\theta}(x)= & \theta^{-n}\mathbb{I}_{\left\{ x_{(n)}\in\left[0,\theta\right]\right\} },x\in\mathbb{R}^{n}
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
For 
\begin_inset Formula $\delta$
\end_inset

 as defined in the problem, we have for any 
\begin_inset Formula $\theta_{1}>\theta_{0},$
\end_inset

 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat}{1}
p_{\theta_{1}}(x)> & \theta_{0}^{n}\theta_{1}^{-n}p_{\theta_{0}}(x)\\
\Leftrightarrow\mathbb{I}_{\left\{ x_{(n)}\in\left[0,\theta_{1}\right]\right\} }> & \mathbb{I}_{\left\{ x_{(n)}\in\left[0,\theta_{0}\right]\right\} }\\
\Leftrightarrow x_{(n)}\in & \left(\theta_{0},\theta_{1}\right)\\
\Rightarrow\delta(x)= & 1\\
p_{\theta_{1}}(x)< & \theta_{0}^{n}\theta_{1}^{-n}p_{\theta_{0}}(x)\label{eq:10}\\
\Leftrightarrow\mathbb{I}_{\left\{ x_{(n)}\in\left[0,\theta_{1}\right]\right\} }> & \mathbb{I}_{\left\{ x_{(n)}\in\left[0,\theta_{0}\right]\right\} }
\end{alignat}

\end_inset


\end_layout

\begin_layout Proof
The last statement is never true when 
\begin_inset Formula $\theta_{1}>\theta_{0},$
\end_inset

 so the set of 
\begin_inset Formula $x$
\end_inset

 that sastifies (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:10"

\end_inset

) is empty.
 So with 
\begin_inset Formula $k=\theta_{0}^{n}\theta_{1}^{-n}$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
\delta(x)= & \begin{cases}
1 & \mbox{when }p_{\theta_{1}}(x)>kp_{\theta_{0}}(x)\\
0 & \mbox{when }p_{\theta_{1}}(x)<kp_{\theta_{0}}(x)
\end{cases}
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
(The statement 
\begin_inset Formula $\delta(x)=a,\forall x\in\emptyset$
\end_inset

 is True for any 
\begin_inset Formula $a$
\end_inset

) 
\end_layout

\begin_layout Proof
So by Simple vs.
 Simple Testing Theorem, we have 
\begin_inset Formula $\delta(x)$
\end_inset

 is MP at level 
\begin_inset Formula $\alpha,$
\end_inset

 for 
\begin_inset Formula $k=\theta_{0}^{n}\theta_{1}^{-n}$
\end_inset

.
 
\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $\delta$
\end_inset

 was defined independently of 
\begin_inset Formula $\theta_{1},$
\end_inset

 and we have 
\begin_inset Formula $\mathbb{E}_{\theta_{0}}\delta(X)=\alpha,$
\end_inset

 and 
\begin_inset Formula $\mathbb{E}_{\theta}\delta(X)\le\alpha,\forall\theta\le\theta_{0},$
\end_inset

 the test 
\begin_inset Formula $\delta$
\end_inset

 is also UMP for testing 
\begin_inset Formula $H_{0}:\theta\le\theta_{0}$
\end_inset

 against 
\begin_inset Formula $H_{1}:\theta>\theta_{0}.$
\end_inset

 
\end_layout

\begin_layout Proof
______________________
\end_layout

\begin_layout Proof
(b) Let 
\begin_inset Formula $\delta$
\end_inset

 be as defined in the problem.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
\mathbb{E}_{\theta_{0}}\delta(X)= & \mathbb{P}_{\theta_{0}}\left[X_{(n)}\le\theta\alpha^{1/n}\right]\\
= & \prod_{i=1}^{n}\mathbb{P}_{\theta_{0}}\left[X_{i}\le\theta\alpha^{1/n}\right]\\
= & \left(\alpha^{1/n}\right)^{n}=\alpha
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
For the case 
\begin_inset Formula $\theta_{1}>\theta_{0},$
\end_inset

 choose 
\begin_inset Formula $k=\theta_{0}^{n}\theta_{1}^{-n},$
\end_inset

 we use the same reasoning as in 
\begin_inset Formula $(a),$
\end_inset

 we have 
\begin_inset Formula $\delta$
\end_inset

 is MP for testing 
\begin_inset Formula $H_{0}:\theta=\theta_{0}$
\end_inset

 against 
\begin_inset Formula $H_{1}:\theta=\theta_{1}$
\end_inset

.
 
\end_layout

\begin_layout Proof
For the case 
\begin_inset Formula $\theta_{0}\alpha^{1/n}<\theta_{1}<\theta_{0},$
\end_inset

 we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
p_{\theta_{1}}(x)> & \theta_{0}^{n}\theta_{1}^{-n}p_{\theta_{0}}(x)\\
\Leftrightarrow\mathbb{I}_{\left\{ x_{(n)}\in\left[0,\theta_{1}\right]\right\} }> & \mathbb{I}_{\left\{ x_{(n)}\in\left[0,\theta_{0}\right]\right\} }\mbox{ which is always False}\\
p_{\theta_{1}}(x)< & \theta_{0}^{n}\theta_{1}^{-n}p_{\theta_{0}}(x)\\
\Leftrightarrow\mathbb{I}_{\left\{ x_{(n)}\in\left[0,\theta_{1}\right]\right\} }< & \mathbb{I}_{\left\{ x_{(n)}\in\left[0,\theta_{0}\right]\right\} }\\
\Leftrightarrow x_{(n)}\in & \left[\theta_{1},\theta\right]\\
\Rightarrow\delta(x)= & 0\\
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
So by the Simple vs.
 Simple Testing Theorem, we have 
\begin_inset Formula $\delta(X)$
\end_inset

 is MP at level 
\begin_inset Formula $\alpha,$
\end_inset

 for 
\begin_inset Formula $k=\theta_{0}^{n}\theta_{1}^{-n}.$
\end_inset

 
\end_layout

\begin_layout Proof
Finally, for the case 
\begin_inset Formula $\theta_{1}\le\theta_{0}\alpha^{1/n},$
\end_inset

 with 
\begin_inset Formula $k=0,$
\end_inset

we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
p_{\theta_{1}}(x)> & kp_{\theta_{0}}(x)\\
\Leftrightarrow p_{\theta_{1}}(x)> & 0\\
\Leftrightarrow x_{(n)}\in & [0,\theta_{1}]\\
\Rightarrow\delta(x)= & 1\\
p_{\theta_{1}}(x)< & kp_{\theta_{0}}(x)\\
\Leftrightarrow p_{\theta_{1}}(x)< & 0
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
The last statement is never true.
 So also by the Simple vs.
 Simple Testing Theorem, we have 
\begin_inset Formula $\delta(X)$
\end_inset

 is MP at level 
\begin_inset Formula $\alpha,$
\end_inset

 for 
\begin_inset Formula $k=0$
\end_inset

.
\end_layout

\begin_layout Proof
From the three cases, since 
\begin_inset Formula $\delta(X)$
\end_inset

 was defined independently of 
\begin_inset Formula $\theta_{1},$
\end_inset

 we have 
\begin_inset Formula $\delta(X)$
\end_inset

 is UMP.
 
\end_layout

\begin_layout Proof
___________________
\end_layout

\begin_layout Proof
Now we need to show that it is unique.
 Let 
\begin_inset Formula $\lambda$
\end_inset

 be the Lebesque measure in 
\begin_inset Formula $\mathbb{R}^{n},$
\end_inset

 we have the uniform distribution in 
\begin_inset Formula $\mathbb{R}^{n}$
\end_inset

 is absolutely continuous w.r.t 
\begin_inset Formula $\lambda$
\end_inset

.
 Let 
\begin_inset Formula $\delta^{*}$
\end_inset

 be any UMP test for the population.
 Define: 
\begin_inset Formula $D=\left\{ x\mid\delta(x)\neq\delta^{*}(x)\right\} ,D_{1}=D$
\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
D= & \left\{ x\mid\delta(x)\neq\delta^{*}(x)\right\} \\
D_{1}= & D\cap\left\{ x\mid x_{(n)}\le\theta_{0}\alpha^{1/n}\right\} \\
D_{2}= & D\cap\left\{ x\mid\theta_{0}\alpha^{1/n}<x_{(n)}\le\theta_{0}\right\} \\
D_{3}= & D\cap\left\{ x\mid\theta_{0}<x_{(n)}<K\right\} 
\end{alignat*}

\end_inset

 for some 
\begin_inset Formula $K>\theta_{0}.$
\end_inset

 Because 
\begin_inset Formula $\delta$
\end_inset

 and 
\begin_inset Formula $\delta^{*}$
\end_inset

 are both UMP, we have: 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat}{1}
\mathbb{E}_{\theta}\delta(X)= & \mathbb{E}_{\theta}\delta^{*}(X),\forall\theta>0\\
\Rightarrow\int_{x_{(n)}<\theta}\left[\delta(x)-\delta^{*}(x)\right]d\lambda(x)= & 0,\forall\theta>0\label{eq:13}\\
\int_{D_{1}}\left[1-\delta^{*}(x)\right]d\lambda(x)= & \int_{x_{(n)}<\theta_{0}\alpha^{1/n}}\left[\delta(x)-\delta^{*}(x)\right]d\lambda(x)\label{eq:14}
\end{alignat}

\end_inset


\end_layout

\begin_layout Proof
For RHS of (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:14"

\end_inset

), apply what we have in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:13"

\end_inset

) for 
\begin_inset Formula $\theta=\theta_{0}\alpha^{1/n}$
\end_inset

, we have RHS(
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:14"

\end_inset

) = 0.
 So 
\begin_inset Formula $\lambda(D_{1})=0$
\end_inset

 because otherwise, 
\begin_inset Formula $\int_{D_{1}}\left[1-\delta^{*}(x)\right]d\lambda(x)>0$
\end_inset

 as 
\begin_inset Formula $1>\delta^{*}(x)$
\end_inset

 over the region 
\begin_inset Formula $D_{1}$
\end_inset

 of integration.
 
\end_layout

\begin_layout Proof
For 
\begin_inset Formula $D_{2},$
\end_inset

 we also have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
\int_{D_{2}}\left[-\delta^{*}(x)\right]d\lambda(x)= & \int_{x_{(n)}<\theta_{0}}\left[\delta(x)-\delta^{*}(x)\right]d\lambda(x)-\int_{x_{(n)}<\theta_{0}\alpha^{1/n}}\left[\delta(x)-\delta^{*}(x)\right]d\lambda(x)\\
= & 0
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
So we also have 
\begin_inset Formula $\lambda(D_{2})=0$
\end_inset

.
 
\end_layout

\begin_layout Proof
Finally for 
\begin_inset Formula $D_{3},$
\end_inset

 we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
\int_{D_{3}}\left[1-\delta^{*}(x)\right]d\lambda(x)= & \int_{x_{(n)}<K}\left[\delta(x)-\delta^{*}(x)\right]d\lambda(x)-\int_{x_{(n)}<\theta_{0}}\left[\delta(x)-\delta^{*}(x)\right]d\lambda(x)\\
= & 0
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
Thus 
\begin_inset Formula $\lambda(D_{3})=0.$
\end_inset

 
\end_layout

\begin_layout Proof
Hence, for all 
\begin_inset Formula $K>\theta_{0},$
\end_inset

 we have 
\begin_inset Formula $\lambda(D\cap\left\{ x\mid x_{(n)}<K\right\} )=0,$
\end_inset

 this implies 
\begin_inset Formula $\lambda(D)=0$
\end_inset

.
 
\end_layout

\begin_layout Proof
So 
\begin_inset Formula $\delta(X)$
\end_inset

 is unique (any other UMP disagree with 
\begin_inset Formula $\delta(X)$
\end_inset

 in a set of Lebesque measure 0)
\end_layout

\begin_layout Problem
Exponential Distribution
\end_layout

\begin_layout Proof
(a) We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
p_{X_{i}\mid\beta}= & \frac{1}{\beta t_{i}}\exp\left\{ -\frac{x_{i}}{\beta t_{i}}\right\} \\
p_{X\mid\beta}= & \prod\frac{1}{\beta t_{i}}\exp\left\{ -\frac{x_{i}}{\beta t_{i}}\right\} \\
\log p_{X\mid\beta}= & -n\log\beta-\sum_{i=1}^{n}\log t_{i}-\frac{1}{\beta}\sum_{i=1}^{n}\frac{x_{i}}{t_{i}}\\
\frac{\partial\log p_{X\mid\beta}}{\partial\beta}= & -\frac{n}{\beta}+\frac{1}{\beta^{2}}\sum_{i=1}^{n}\frac{x_{i}}{t_{i}}=0\\
\Leftrightarrow\hat{\beta}_{MLE}= & \frac{1}{n}\sum_{i=1}^{n}\frac{X_{i}}{t_{i}}
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
(b) We have 
\begin_inset Formula $Y_{i}=X_{i}/t_{i}$
\end_inset

 are i.i.d with exponential distribution mean parameter 
\begin_inset Formula $\beta$
\end_inset

.
 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
\frac{\partial^{2}\log p_{Y_{i}\mid\beta}}{\partial\beta^{2}}= & \frac{1}{\beta^{2}}-\frac{2}{\beta^{3}}Y_{i}\\
I(\beta)= & \mathbb{E}\left[-\frac{\partial^{2}\log p_{Y_{i}\mid\beta}}{\partial\beta^{2}}\right]\\
= & -\left(\frac{1}{\beta^{2}}-\frac{2}{\beta^{3}}\beta\right)\\
= & \frac{1}{\beta^{2}}
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
By the asymptotic theory of MLE, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
\sqrt{n}(\beta-\hat{\beta}_{n})\rightarrow^{d} & \mathcal{N}\left(0,\frac{1}{I(\beta)}\right)=\mathcal{N}\left(0,\beta^{2}\right)
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
(c) We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
G(X)= & \log p(X;\hat{\beta}_{n})-\log p(X;1)\\
= & -n\log\hat{\beta}_{n}-\sum_{i=1}^{n}\log t_{i}-\frac{1}{\hat{\beta}_{n}}\sum\frac{x_{i}}{t_{i}}+\sum_{i=1}^{n}\log t_{i}+\sum\frac{x_{i}}{t_{i}}\\
= & -n\log\hat{\beta}_{n}-n+n\hat{\beta}_{n}\\
= & n(\hat{\beta}_{n}-\log\hat{\beta}_{n}-1)
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
since 
\begin_inset Formula $\hat{\beta}_{n}=\frac{1}{n}\sum_{i=1}^{n}\frac{x_{i}}{t_{i}}$
\end_inset

.
 
\end_layout

\begin_layout Proof
(d) Let 
\begin_inset Formula $\hat{\alpha}_{n}=\hat{\beta}_{n}-1,$
\end_inset

 under the null, we have: 
\begin_inset Formula $\sqrt{n}(\hat{\alpha}_{n})\rightarrow^{d}\mathcal{N}(0,1)$
\end_inset

, thus 
\begin_inset Formula $n\hat{\alpha}_{n}^{2}\rightarrow^{d}\mathcal{X}_{1}^{2}.$
\end_inset

 
\end_layout

\begin_layout Proof
Now using Taylor series for 
\begin_inset Formula $\log(x+1)$
\end_inset

, we have: 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
2G(X)= & 2n\left(\hat{\beta}_{n}-\log\hat{\beta}_{n}-1\right)\\
= & 2n\left(\hat{\alpha}_{n}-\log\left(\hat{\alpha}+1\right)\right)\\
= & 2n\left(\hat{\alpha}_{n}-\hat{\alpha}_{n}+\frac{\left(\hat{\alpha}_{n}\right)^{2}}{2}-\frac{\left(\hat{\alpha}_{n}^{*}\right)^{3}}{3}\right)\\
= & n\left(\hat{\alpha}_{n}\right)^{2}-\frac{2n}{3}\left(\hat{\alpha}_{n}^{*}\right)^{3}
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
For 
\begin_inset Formula $\hat{\alpha}_{n}^{*}$
\end_inset

 is between 0 and 
\begin_inset Formula $\hat{\alpha}_{n}.$
\end_inset

 Now we have 
\begin_inset Formula $n\left(\hat{\alpha}_{n}\right)^{2}\Rightarrow\mathcal{X}_{0}^{1},$
\end_inset

 and 
\begin_inset Formula $n\left|\hat{\alpha}_{n}^{*}\right|^{3}\le n\left|\hat{\alpha}_{n}\right|^{3}$
\end_inset

 converges to 
\begin_inset Formula $0$
\end_inset

 in probability since.
 So by the Slutsky theorem, we have 
\begin_inset Formula $2G(X)\rightarrow^{d}\mathcal{X}_{0}^{1}.$
\end_inset

 
\end_layout

\begin_layout Problem
Bayesian Testing
\end_layout

\begin_layout Proof
(a) For each 
\begin_inset Formula $X=x,$
\end_inset

 given that the true model is 
\begin_inset Formula $p_{0},$
\end_inset

 the chance of wrongly accepting 
\begin_inset Formula $p_{1}$
\end_inset

 is 
\begin_inset Formula $\varphi(x)$
\end_inset

.
 Given that the true model is 
\begin_inset Formula $p_{1},$
\end_inset

 the chance of wrongly accepting 
\begin_inset Formula $p_{0}$
\end_inset

 is 
\begin_inset Formula $1-\varphi(x).$
\end_inset

 Thus taking the expectation, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
R(\varphi)= & \mathbb{E}\left[\mathbb{I}_{\left\{ \Theta=0\right\} }\varphi(X)+\mathbb{I}_{\left\{ \Theta=1\right\} }(1-\varphi(X))\right]\\
= & \mathbb{E}\left[\varphi(X)^{1-\Theta}(1-\varphi(X))^{\Theta}\right]
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
(b) Using tower property, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
R(\varphi)= & \mathbb{E}\left[\mathbb{E}\left[\mathbb{I}_{\left\{ \Theta=0\right\} }\varphi(X)+\mathbb{I}_{\left\{ \Theta=1\right\} }(1-\varphi(X))\mid\Theta\right]\right]\\
= & (1-p)\mathbb{E}_{0}(\varphi)+p\mathbb{E}_{1}(\varphi)\\
= & \int(1-p)\varphi(x)p_{0}(x)dx+\int p\varphi(x)p_{1}(x)dx
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
(c) For those 
\begin_inset Formula $x$
\end_inset

 such that 
\begin_inset Formula $(1-p)p_{0}(x)<pp_{1}(x),$
\end_inset

 
\begin_inset Formula $R(\varphi)$
\end_inset

 is minimized when 
\begin_inset Formula $\varphi(x)=0$
\end_inset

.
\end_layout

\begin_layout Proof
Similarly for those 
\begin_inset Formula $x$
\end_inset

 such that 
\begin_inset Formula $(1-p)p_{0}(x)>pp_{1}(x),$
\end_inset

 
\begin_inset Formula $R(\varphi)$
\end_inset

 is minimized when 
\begin_inset Formula $\varphi(x)=1$
\end_inset

.
 So the test function 
\begin_inset Formula $\varphi^{*}$
\end_inset

 minimizing 
\begin_inset Formula $R(\varphi)$
\end_inset

 is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
\varphi^{*}(x)= & \begin{cases}
1, & \mbox{if }p_{0}(x)>\frac{p}{1-p}p_{1}(x)\\
0, & \mbox{if }p_{1}(x)<\frac{p}{1-p}p_{1}(x)
\end{cases}
\end{alignat*}

\end_inset


\end_layout

\begin_layout Proof
The critical value 
\begin_inset Formula $k=\frac{p}{1-p}$
\end_inset

.
 
\end_layout

\end_body
\end_document
